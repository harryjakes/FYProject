{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ht545-FinalYearProject-ColumnImputationGANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOB0BcHk+UcG0LkYXfdQFuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryjakes/FYProject/blob/main/ht545_FinalYearProject_ColumnImputationGANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fquTm_YGy3",
        "outputId": "22bf5574-eb8a-409a-c5ef-e14caadce5db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIU1iH7Rdk9S"
      },
      "source": [
        "#MISGAN MR-NET Column imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn4za8QhYrTu"
      },
      "source": [
        "#All credit goes to original authors of misGAN : Steven Cheng-Xian Li, Benjamin M. Marlin\n",
        "\n",
        "#Paper : Li, S.C., Jiang, B., & Marlin, B.M. (2019). MisGAN: Learning from Incomplete Data with Generative Adversarial Networks. ArXiv, abs/1902.09599.\n",
        "\n",
        "#Project page (with all github links): https://github.com/steveli/misgan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhgcVH2_j3nB"
      },
      "source": [
        "#To RUN\n",
        "\n",
        "#Place the dataset of choice within the dataset folder, for example if using MRNet Coronal, this will look as follows:\n",
        "\n",
        "#dataset>\n",
        "#        MRNetCoronal>\n",
        "#                     001.jpg...\n",
        "#                     ... \n",
        "#                     xxx.jpg\n",
        "\n",
        "#Once done, specify the column length to impute within the masked_image file. This line has been highlighted within the masked_image.py script itself.\n",
        "\n",
        "#Then to run, simply run !python image_misgan_impute.py, results will apear within the results>MRNet> folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hrf6oVE3NPt"
      },
      "source": [
        "!python image_misgan_impute.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmzE6U--dgan"
      },
      "source": [
        "#MISGAN PVAE MR-NET Column imputation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W8M_a7-Yymp"
      },
      "source": [
        "#All credit goes to original authors of P-VaE misGAN : Steven Cheng-Xian Li, Benjamin M. Marlin\n",
        "\n",
        "#Paper : Li, S.C., & Marlin, B.M. (2020). Learning from Irregularly-Sampled Time Series: A Missing Data Perspective. ICML.\n",
        "#Project page (with all github links): https://github.com/steveli/partial-encoder-decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpbr0FITjce2"
      },
      "source": [
        "#To RUN\n",
        "\n",
        "#Place the dataset of choice within the dataset folder, for example if using MRNet Coronal, this will look as follows:\n",
        "\n",
        "#dataset>\n",
        "#        MRNetCoronal>\n",
        "#                     001.jpg...\n",
        "#                     ... \n",
        "#                     xxx.jpg\n",
        "\n",
        "#Once done, specify the column length to impute within the masked_image file. This line has been highlighted within the masked_image.py script itself.\n",
        "\n",
        "#Then to run, simply run !python pvae.py, results will apear within the results>pvae> folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqNrBSaAIky4"
      },
      "source": [
        "!python celeba_pvae.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2UN8Ii9cLnX"
      },
      "source": [
        "#CYCLE GAN MR-NET Column imutation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnjA2maaY4DI"
      },
      "source": [
        "#All credit goes to original authors of cycleGAN : Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros\n",
        "#https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "#Paper : https://arxiv.org/pdf/1703.10593.pdf\n",
        "#Project page (with all github links): https://junyanz.github.io/CycleGAN/\n",
        "\n",
        "#For all pre-processing of databases, please refer to the cell found at the bottom of this notebook.\n",
        "#For pre-trained paths, locate the paths according to the dataset that will be used, then place them into the output folder. \n",
        "#To run train or test with a certain database, !train.py --dataroot [dataset path goes here!] will suffice\n",
        "#When testing, the output will be returned to the corrosponding A or B domain folder within output. \n",
        "\n",
        "\n",
        "#STEP BY STEP GUIDE\n",
        "#Pre-process a database with some given mask, done in the cell found at the bottom of this notebook.\n",
        "#Seperate this database into, training and testing sets. Each training and testing folder must contain a folder named A and B. \n",
        "#A will hold the masked images, B the ground truths. \n",
        "#The folders train and test can then be placed into the cycleGAN dataset folder.\n",
        "\n",
        "#For example:\n",
        "#dataset>\n",
        "#         exampleSETA>\n",
        "#                     testA>\n",
        "#                          A (testing images from the dataset with masks)                          \n",
        "#                     testB>\n",
        "#                          B (testing images from the dataset of ground truths)\n",
        "#                     trainA>\n",
        "#                          A (training images from the dataset with masks)\n",
        "#                     trainB>\n",
        "#                          B (training images from the dataset of ground truths)\n",
        "#                          \n",
        "                         \n",
        "\n",
        "\n",
        "#Once this is as follows, CycleGAN may be trained as follows (assuming we are in correct directory)\n",
        "# !train.py --dataroot [dataset path goes here!] --model cycle_gan and likewise !test.py --dataroot [dataset path goes here!]  --model cycle_gan\n",
        "#Please see train and test files for more variable changes (epochs, batch sizes, learning rate etc)\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uIvOU6zh-wy"
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOJUrmm_fOgH"
      },
      "source": [
        "#Metrics for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rid4Adf5cxI"
      },
      "source": [
        "#To run either the ssim or psnr metric, upon the generated outputs from the test set against their ground truths:\n",
        "\n",
        "#Specify the dataset paths where each is held as follows:\n",
        "generatedImages = glob.glob('some/path/to/generatedImages/*.jpg')\n",
        "groundTruths = glob.glob('some/path/to/groundTruths/*.jpg')\n",
        "\n",
        "#Then running sumOfScores(generatedImages,groundTruths) will return the sum of all ssims & psnrs for each pair.\n",
        "#Dividing by the amount will give the average score for each as shown in the analysis section of the project paper."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGe7bVR2fNoG"
      },
      "source": [
        "import cv2\n",
        "from skimage.metrics import structural_similarity\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import scipy.misc as sm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "\n",
        "def readScaleConvert(first,second):\n",
        "  a = cv2.imread(first)\n",
        "  b = cv2.imread(second)\n",
        "  a = cv2.resize(a, (250,250))\n",
        "  b = cv2.resize(b, (250,250))\n",
        "  a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
        "  b = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
        "  return (a,b)\n",
        "\n",
        "def ssim(a,b):\n",
        "  score, null = structural_similarity(a,b, full=True)\n",
        "  return score\n",
        "\n",
        "def psnr(a,b):\n",
        "  score = peak_signal_noise_ratio(a,b)\n",
        "  return score\n",
        "\n",
        "def sumOfScores(list_one,list_two):\n",
        "  #return all ssim scores for two lists, don't have to be equal will just loop up to the shorter one\n",
        "  ssims = [ssim(a,b) for a,b in [readScaleConvert(list_one[index],list_two[index]) for index in range(min(len(list_one),len(list_two)))]]\n",
        "  psnrs = [psnr(a,b) for a,b in [readScaleConvert(list_one[index],list_two[index]) for index in range(min(len(list_one),len(list_two)))]]\n",
        "  return sum(ssims),sum(psnrs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13hGiWs6AyL"
      },
      "source": [
        "#For the FID evaluation\n",
        "\n",
        "#Specify the paths to each dataset, generated images and ground truths. Then add these to the path variables within the fid_score script in the pytorch_fid folder.\n",
        "#This can be found on line 254 & 256 and is highlighted in the script.\n",
        "\n",
        "#The following lines must be run to import the correct files\n",
        "\n",
        "!pip install pytorch-fid\n",
        "\n",
        "import pytorch_fid\n",
        "\n",
        "!python path/to/fid_score.py \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJUNe3Ek5_QK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYipHrh8gWBg"
      },
      "source": [
        "#Database Pre-processing (i.e 3-D --> 2-D & masking options)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtessG7Ogccm"
      },
      "source": [
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "import random\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GyJXW_sggHY"
      },
      "source": [
        "#MRNet is available to download here : https://stanfordmlgroup.github.io/competitions/mrnet/\n",
        "#These are the glob objects read in during the training, please replace this file name with wherever the downloaded database is stored.\n",
        "\n",
        "coronal = glob.glob('path/to/MRNet-v1.0/MRNet-v1.0/train/coronal/*.npy')\n",
        "sagittal = glob.glob('path/to/MRNet-v1.0/MRNet-v1.0/train/sagittal/*.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQPjLUdCgxq1"
      },
      "source": [
        "def createMaskAndGT(maskLength, databaseGlob, savePath, sliceNumber):\n",
        "  #recommended maskLength is 48\n",
        "  count = 0\n",
        "  for scan in databaseGlob:\n",
        "    image = np.rot90(np.load(scan)[sliceNumber])\n",
        "\n",
        "    mask_start = random.randint(0,13)\n",
        "    image[0:256,16*mask_start:maskLength+16*mask_start] = 0\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    newSavePath = savePath + \"/A/%s.jpg\"%(count)\n",
        "    plt.savefig(newSavePath,bbox_inches='tight',pad_inches = 0) \n",
        "\n",
        "    image = np.rot90(np.load(scan)[sliceNumber])\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    newSavePath = savePath + \"/B/%s.jpg\"%(count)\n",
        "    plt.savefig(newSavePath,bbox_inches='tight',pad_inches = 0)\n",
        "\n",
        "    count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9OoK4t-7XHo"
      },
      "source": [
        "#Example, for the masking of 48 pixels:\n",
        "\n",
        "createMaskAndGT(48,coronal,'path/to/saved/databases/coronal48',20)\n",
        "\n",
        "#Then once this has been done, a split can be made witihin coronal48 into test & training folders."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}